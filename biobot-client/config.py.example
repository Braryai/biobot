# ============================================================================
# BioBot Voice Client Configuration Example
# ============================================================================
# Copy this file to config.py and fill in your actual values

# ============================================================================
# Operation Mode
# ============================================================================
# Choose operation mode:
# - True (OpenWebUI): Full featured mode with OpenWebUI integration, chat persistence, 
#                      knowledge bases, and conversation history
# - False (Standalone): Lightweight mode using only TotalGPT API, no persistence,
#                       ideal for quick questions without OpenWebUI setup
USE_OPENWEBUI = True  # Set to False for standalone mode

# ============================================================================
# Open WebUI Configuration (only used if USE_OPENWEBUI = True)
# ============================================================================
# Open WebUI server URL (no trailing slash)
OPENWEBUI_URL = "http://YOUR_SERVER_IP:PORT"

# Open WebUI API token
# Get from: Settings > Account > API Keys in Open WebUI
OPENWEBUI_TOKEN = "your-openwebui-api-token-here"

# Knowledge Base ID or Name for RAG (optional but recommended for datacenter queries)
# Get from: Workspace > Knowledge in Open WebUI
# Can be either:
#   - A UUID (e.g., "a1b2c3d4-e5f6-7890-abcd-ef1234567890")
#   - A name (e.g., "network_configs" - will search for matching KB)
# Leave as empty string "" if not using knowledge base
KNOWLEDGE_ID = ""

# Default AI model to use (OpenWebUI mode)
# This should match a model available in your Open WebUI instance
DEFAULT_MODEL = "llama3.1:8b"

# ============================================================================
# Standalone Mode Configuration (only used if USE_OPENWEBUI = False)
# ============================================================================
# Model to use in standalone mode (via TotalGPT API)
# Available models: Check https://api.totalgpt.ai/docs for current list
# Examples: "Qwen-Qwen3-30B-A3B", "meta-llama/Meta-Llama-3.1-70B-Instruct", etc.
STANDALONE_MODEL = "Qwen-Qwen3-30B-A3B"

# Model for vision tasks in standalone mode (if using screenshots)
# Must be a vision/multimodal model
STANDALONE_VISION_MODEL = "meta-llama/Llama-3.2-11B-Vision-Instruct"

# ============================================================================
# Speech-to-Text Configuration (STT)
# ============================================================================
# You have 3 options for STT (choose one):

# OPTION 1: LOCAL WHISPER (Recommended - Free & Offline!) ‚≠ê
# Runs Whisper model locally on your Mac - no API calls, no costs!
# Install with: pip install faster-whisper
USE_LOCAL_WHISPER = True

# Model size: "tiny", "base", "small", "medium", "large-v2", "large-v3"
# Smaller = faster, larger = more accurate
# Recommended: "base" for good balance, "small" for better accuracy
LOCAL_WHISPER_MODEL = "base"

# OPTION 2: GROQ API (Free for now, Fast)
# Set to True to use Groq instead of local/OpenAI
# Get key from: https://console.groq.com/keys
USE_GROQ_STT = False
GROQ_API_KEY = "your-groq-api-key-here"

# OPTION 3: OPENAI API (Paid but reliable)
# Only used if USE_LOCAL_WHISPER and USE_GROQ_STT are both False
# Get key from: https://platform.openai.com/api-keys
OPENAI_API_KEY = "your-openai-api-key-here"
OPENAI_STT_MODEL = "whisper-1"

# NOTE: Local Whisper is checked first, then Groq, then OpenAI
# Only one will be used per transcription

# ============================================================================
# Text-to-Speech Configuration (TTS) - OPTIONAL
# ============================================================================
# Enable TTS to have BioBot speak responses back to you
# When enabled, BioBot will read the SUMMARY portion of responses aloud
# The full detailed response is still visible in the Open WebUI frontend
USE_TTS = False

# TotalGPT API Key for Text-to-Speech
# Get from: https://api.totalgpt.ai
TOTALGPT_API_KEY = "your_totalgpt_api_key_here"

# TTS Voice Selection
# Available voices: 
#   Adult Female (AF): af_alloy, af_bella, af_heart, af_jessica, af_nicole, af_sarah
#   British Male (BM): bm_lewis, bm_daniel, bm_george, bm_fable
#   Child Voices: cf_laura, cm_aaron
TTS_VOICE = "af_bella"

# TTS Speed (0.1 to 4.0)
# 1.0 = normal speed, <1.0 = slower, >1.0 = faster
TTS_SPEED = 1.0

# TTS Language Code
# "a" = English, "e" = Spanish, "f" = French, "h" = Hindi, 
# "i" = Italian, "p" = Portuguese, "j" = Japanese, "z" = Chinese
TTS_LANG_CODE = "a"

# ============================================================================
# Trigger Keys
# ============================================================================
# Use modifier keys to avoid interfering with other apps and prevent beeping

# Primary trigger: Records audio + captures screenshot
TRIGGER_KEY_WITH_SCREENSHOT = 'cmd_r'  # Right Command key

# Secondary trigger: Records audio only (no screenshot)
TRIGGER_KEY_AUDIO_ONLY = 'shift_r'  # Right Shift key

# Available options:
# - 'cmd_r' (right command)
# - 'shift_r' (right shift)
# - 'alt_r' (right option/alt)
# - 'ctrl_r' (right control)
# - 'cmd' (left command)
# - 'shift' (left shift)
# - 'alt' (left option/alt)
# - 'ctrl' (left control)

# ============================================================================
# Audio Recording Settings
# ============================================================================
AUDIO_SAMPLE_RATE = 16000  # Hz (16kHz is optimal for Whisper)
AUDIO_CHANNELS = 1  # Mono
MAX_RECORDING_DURATION = 60  # Maximum recording duration in seconds
